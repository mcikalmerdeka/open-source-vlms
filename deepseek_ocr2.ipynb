{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9fd5f712",
   "metadata": {},
   "source": [
    "# DeepSeek-OCR-2 Google Colab Demo\n",
    "\n",
    "This notebook allows you to run DeepSeek-OCR-2 for document OCR, markdown conversion, and text localization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae41db19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Install uv package manager\n",
    "!uv pip install uv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d8429f9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# PACKAGE INSTALLATION - STEP 1: Install Core Packages\n",
    "# ============================================================================\n",
    "# Install main packages first\n",
    "!uv pip install -q transformers==4.46.3 tokenizers==0.20.3 accelerate einops addict easydict PyMuPDF hf_transfer gradio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50b0cc26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# PACKAGE INSTALLATION - STEP 2: Install Flash Attention\n",
    "# ============================================================================\n",
    "import sys\n",
    "import torch\n",
    "\n",
    "print(f\"Python version: {sys.version}\")\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"CUDA version: {torch.version.cuda}\")\n",
    "\n",
    "# Check if we need to install or if it's already installed\n",
    "try:\n",
    "    import flash_attn\n",
    "    print(f\"\\n‚úì Flash Attention already installed: v{flash_attn.__version__}\")\n",
    "    print(\"If you're getting import errors, restart the runtime!\")\n",
    "except ImportError:\n",
    "    print(\"\\nInstalling Flash Attention 2.7.3 for Python 3.12...\")\n",
    "    # !uv pip install flash-attn==2.7.3 --no-build-isolation\n",
    "    !uv pip install https://github.com/Dao-AILab/flash-attention/releases/download/v2.7.3/flash_attn-2.7.3+cu12torch2.6cxx11abiFALSE-cp312-cp312-linux_x86_64.whl\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"‚úì Flash Attention 2.7.3 installed!\")\n",
    "    print(\"=\"*70)\n",
    "    print(\"CRITICAL: YOU MUST RESTART THE RUNTIME NOW!\")\n",
    "    print(\"Go to: Runtime -> Restart runtime\")\n",
    "    print(\"After restart, skip cells 1-3 and run from cell 4 (imports)\")\n",
    "    print(\"=\"*70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "85bb4dad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# IMPORTS\n",
    "# ============================================================================\n",
    "import gradio as gr\n",
    "from transformers import AutoModel, AutoTokenizer\n",
    "import torch\n",
    "import os\n",
    "import sys\n",
    "import tempfile\n",
    "import shutil\n",
    "from PIL import Image, ImageDraw, ImageFont, ImageOps\n",
    "import fitz\n",
    "import re\n",
    "import numpy as np\n",
    "import base64\n",
    "from io import StringIO, BytesIO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cb74f94",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# MODEL CONFIGURATION\n",
    "# ============================================================================\n",
    "# Following the original Space implementation\n",
    "MODEL_NAME = 'deepseek-ai/DeepSeek-OCR-2'\n",
    "\n",
    "print(\"Loading tokenizer...\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME, trust_remote_code=True)\n",
    "\n",
    "print(\"Loading model...\")\n",
    "# Try flash attention first, fallback to sdpa/eager if it fails\n",
    "try:\n",
    "    print(\"Attempting to load with Flash Attention 2...\")\n",
    "    model = AutoModel.from_pretrained(\n",
    "        MODEL_NAME, \n",
    "        _attn_implementation='flash_attention_2',\n",
    "        torch_dtype=torch.bfloat16,\n",
    "        trust_remote_code=True, \n",
    "        use_safetensors=True\n",
    "    )\n",
    "    model = model.eval().cuda()\n",
    "    print(\"‚úì Model loaded successfully with Flash Attention 2!\")\n",
    "except Exception as e:\n",
    "    print(f\"‚ö†Ô∏è Flash Attention failed: {str(e)[:100]}\")\n",
    "    print(\"Trying with SDPA (scaled dot product attention)...\")\n",
    "    try:\n",
    "        model = AutoModel.from_pretrained(\n",
    "            MODEL_NAME, \n",
    "            _attn_implementation='sdpa',\n",
    "            torch_dtype=torch.bfloat16,\n",
    "            trust_remote_code=True, \n",
    "            use_safetensors=True\n",
    "        )\n",
    "        model = model.eval().cuda()\n",
    "        print(\"‚úì Model loaded successfully with SDPA (slower but works)!\")\n",
    "    except Exception as e2:\n",
    "        print(f\"‚ö†Ô∏è SDPA also failed: {str(e2)[:100]}\")\n",
    "        print(\"Falling back to eager attention (slowest but most compatible)...\")\n",
    "        model = AutoModel.from_pretrained(\n",
    "            MODEL_NAME, \n",
    "            _attn_implementation='eager',\n",
    "            torch_dtype=torch.bfloat16,\n",
    "            trust_remote_code=True, \n",
    "            use_safetensors=True\n",
    "        )\n",
    "        model = model.eval().cuda()\n",
    "        print(\"‚úì Model loaded successfully with eager attention!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44eebe25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# CONFIGURATION PARAMETERS\n",
    "# ============================================================================\n",
    "BASE_SIZE = 1024\n",
    "IMAGE_SIZE = 768\n",
    "CROP_MODE = True\n",
    "\n",
    "TASK_PROMPTS = {\n",
    "    \"üìã Markdown\": {\"prompt\": \"<image>\\n<|grounding|>Convert the document to markdown.\", \"has_grounding\": True},\n",
    "    \"üìù Free OCR\": {\"prompt\": \"<image>\\nFree OCR.\", \"has_grounding\": False},\n",
    "    \"üìç Locate\": {\"prompt\": \"<image>\\nLocate <|ref|>text<|/ref|> in the image.\", \"has_grounding\": True},\n",
    "    \"üîç Describe\": {\"prompt\": \"<image>\\nDescribe this image in detail.\", \"has_grounding\": False},\n",
    "    \"‚úèÔ∏è Custom\": {\"prompt\": \"\", \"has_grounding\": False}\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "174d7407",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# UTILITY FUNCTIONS - TEXT PROCESSING\n",
    "# ============================================================================\n",
    "def extract_grounding_references(text):\n",
    "    \"\"\"Extract grounding references from model output\"\"\"\n",
    "    pattern = r'(<\\|ref\\|>(.*?)<\\|/ref\\|><\\|det\\|>(.*?)<\\|/det\\|>)'\n",
    "    return re.findall(pattern, text, re.DOTALL)\n",
    "\n",
    "def clean_output(text, include_images=False):\n",
    "    \"\"\"Clean the output text by removing grounding references\"\"\"\n",
    "    if not text:\n",
    "        return \"\"\n",
    "    pattern = r'(<\\|ref\\|>(.*?)<\\|/ref\\|><\\|det\\|>(.*?)<\\|/det\\|>)'\n",
    "    matches = re.findall(pattern, text, re.DOTALL)\n",
    "    img_num = 0\n",
    "    \n",
    "    for match in matches:\n",
    "        if '<|ref|>image<|/ref|>' in match[0]:\n",
    "            if include_images:\n",
    "                text = text.replace(match[0], f'\\n\\n**[Figure {img_num + 1}]**\\n\\n', 1)\n",
    "                img_num += 1\n",
    "            else:\n",
    "                text = text.replace(match[0], '', 1)\n",
    "        else:\n",
    "            text = re.sub(rf'(?m)^[^\\n]*{re.escape(match[0])}[^\\n]*\\n?', '', text)\n",
    "    \n",
    "    text = text.replace('\\\\coloneqq', ':=').replace('\\\\eqqcolon', '=:')\n",
    "    \n",
    "    return text.strip()\n",
    "\n",
    "def embed_images(markdown, crops):\n",
    "    \"\"\"Embed cropped images into markdown as base64\"\"\"\n",
    "    if not crops:\n",
    "        return markdown\n",
    "    for i, img in enumerate(crops):\n",
    "        buf = BytesIO()\n",
    "        img.save(buf, format=\"PNG\")\n",
    "        b64 = base64.b64encode(buf.getvalue()).decode()\n",
    "        markdown = markdown.replace(f'**[Figure {i + 1}]**', f'\\n\\n![Figure {i + 1}](data:image/png;base64,{b64})\\n\\n', 1)\n",
    "    return markdown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ff1d915",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# UTILITY FUNCTIONS - IMAGE PROCESSING\n",
    "# ============================================================================\n",
    "def draw_bounding_boxes(image, refs, extract_images=False):\n",
    "    \"\"\"Draw bounding boxes on image based on grounding references\"\"\"\n",
    "    img_w, img_h = image.size\n",
    "    img_draw = image.copy()\n",
    "    draw = ImageDraw.Draw(img_draw)\n",
    "    overlay = Image.new('RGBA', img_draw.size, (0, 0, 0, 0))\n",
    "    draw2 = ImageDraw.Draw(overlay)\n",
    "    \n",
    "    # Try to load a font, fallback to default if not available\n",
    "    try:\n",
    "        font = ImageFont.truetype(\"/usr/share/fonts/truetype/dejavu/DejaVuSans-Bold.ttf\", 15)\n",
    "    except:\n",
    "        try:\n",
    "            # Try alternative font path for Colab\n",
    "            font = ImageFont.truetype(\"/usr/share/fonts/truetype/liberation/LiberationSans-Bold.ttf\", 15)\n",
    "        except:\n",
    "            font = ImageFont.load_default()\n",
    "    \n",
    "    crops = []\n",
    "    color_map = {}\n",
    "    np.random.seed(42)\n",
    "\n",
    "    for ref in refs:\n",
    "        label = ref[1]\n",
    "        if label not in color_map:\n",
    "            color_map[label] = (np.random.randint(50, 255), np.random.randint(50, 255), np.random.randint(50, 255))\n",
    "\n",
    "        color = color_map[label]\n",
    "        coords = eval(ref[2])\n",
    "        color_a = color + (60,)\n",
    "        \n",
    "        for box in coords:\n",
    "            x1, y1, x2, y2 = int(box[0]/999*img_w), int(box[1]/999*img_h), int(box[2]/999*img_w), int(box[3]/999*img_h)\n",
    "            \n",
    "            if extract_images and label == 'image':\n",
    "                crops.append(image.crop((x1, y1, x2, y2)))\n",
    "            \n",
    "            width = 5 if label == 'title' else 3\n",
    "            draw.rectangle([x1, y1, x2, y2], outline=color, width=width)\n",
    "            draw2.rectangle([x1, y1, x2, y2], fill=color_a)\n",
    "            \n",
    "            text_bbox = draw.textbbox((0, 0), label, font=font)\n",
    "            tw, th = text_bbox[2] - text_bbox[0], text_bbox[3] - text_bbox[1]\n",
    "            ty = max(0, y1 - 20)\n",
    "            draw.rectangle([x1, ty, x1 + tw + 4, ty + th + 4], fill=color)\n",
    "            draw.text((x1 + 2, ty + 2), label, font=font, fill=(255, 255, 255))\n",
    "    \n",
    "    img_draw.paste(overlay, (0, 0), overlay)\n",
    "    return img_draw, crops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63fa1967",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# CORE PROCESSING FUNCTIONS\n",
    "# ============================================================================\n",
    "def process_image(image, task, custom_prompt):\n",
    "    \"\"\"Process a single image with the selected task\"\"\"\n",
    "    if image is None:\n",
    "        return \"Error: Upload an image\", \"\", \"\", None, []\n",
    "    if task in [\"‚úèÔ∏è Custom\", \"üìç Locate\"] and not custom_prompt.strip():\n",
    "        return \"Please enter a prompt\", \"\", \"\", None, []\n",
    "    \n",
    "    # Convert image to RGB if needed\n",
    "    if image.mode in ('RGBA', 'LA', 'P'):\n",
    "        image = image.convert('RGB')\n",
    "    image = ImageOps.exif_transpose(image)\n",
    "    \n",
    "    # Prepare prompt based on task\n",
    "    if task == \"‚úèÔ∏è Custom\":\n",
    "        prompt = f\"<image>\\n{custom_prompt.strip()}\"\n",
    "        has_grounding = '<|grounding|>' in custom_prompt\n",
    "    elif task == \"üìç Locate\":\n",
    "        prompt = f\"<image>\\nLocate <|ref|>{custom_prompt.strip()}<|/ref|> in the image.\"\n",
    "        has_grounding = True\n",
    "    else:\n",
    "        prompt = TASK_PROMPTS[task][\"prompt\"]\n",
    "        has_grounding = TASK_PROMPTS[task][\"has_grounding\"]\n",
    "    \n",
    "    # Save image temporarily\n",
    "    tmp = tempfile.NamedTemporaryFile(delete=False, suffix='.jpg')\n",
    "    image.save(tmp.name, 'JPEG', quality=95)\n",
    "    tmp.close()\n",
    "    out_dir = tempfile.mkdtemp()\n",
    "    \n",
    "    # Capture model output\n",
    "    stdout = sys.stdout\n",
    "    sys.stdout = StringIO()\n",
    "    \n",
    "    model.infer(\n",
    "        tokenizer=tokenizer, \n",
    "        prompt=prompt, \n",
    "        image_file=tmp.name, \n",
    "        output_path=out_dir,\n",
    "        base_size=BASE_SIZE, \n",
    "        image_size=IMAGE_SIZE, \n",
    "        crop_mode=CROP_MODE,\n",
    "        save_results=False\n",
    "    )\n",
    "    \n",
    "    # Filter debug output\n",
    "    debug_filters = ['PATCHES', '====', 'BASE:', 'directly resize', 'NO PATCHES', 'torch.Size', '%|']\n",
    "    result = '\\n'.join([l for l in sys.stdout.getvalue().split('\\n') \n",
    "                        if l.strip() and not any(s in l for s in debug_filters)]).strip()\n",
    "    sys.stdout = stdout\n",
    "    \n",
    "    # Cleanup\n",
    "    os.unlink(tmp.name)\n",
    "    shutil.rmtree(out_dir, ignore_errors=True)\n",
    "    \n",
    "    if not result:\n",
    "        return \"No text detected\", \"\", \"\", None, []\n",
    "    \n",
    "    # Process output\n",
    "    cleaned = clean_output(result, False)\n",
    "    markdown = clean_output(result, True)\n",
    "    \n",
    "    img_out = None\n",
    "    crops = []\n",
    "    \n",
    "    # Draw bounding boxes if grounding is enabled\n",
    "    if has_grounding and '<|ref|>' in result:\n",
    "        refs = extract_grounding_references(result)\n",
    "        if refs:\n",
    "            img_out, crops = draw_bounding_boxes(image, refs, True)\n",
    "    \n",
    "    markdown = embed_images(markdown, crops)\n",
    "    \n",
    "    return cleaned, markdown, result, img_out, crops\n",
    "\n",
    "def process_pdf(path, task, custom_prompt, page_num):\n",
    "    \"\"\"Process a PDF file by converting specified page to image\"\"\"\n",
    "    doc = fitz.open(path)\n",
    "    total_pages = len(doc)\n",
    "    if page_num < 1 or page_num > total_pages:\n",
    "        doc.close()\n",
    "        return f\"Invalid page number. PDF has {total_pages} pages.\", \"\", \"\", None, []\n",
    "    page = doc.load_page(page_num - 1)\n",
    "    pix = page.get_pixmap(matrix=fitz.Matrix(300/72, 300/72), alpha=False)\n",
    "    img = Image.open(BytesIO(pix.tobytes(\"png\")))\n",
    "    doc.close()\n",
    "    \n",
    "    return process_image(img, task, custom_prompt)\n",
    "\n",
    "def process_file(path, task, custom_prompt, page_num):\n",
    "    \"\"\"Process either an image or PDF file\"\"\"\n",
    "    if not path:\n",
    "        return \"Error: Upload a file\", \"\", \"\", None, []\n",
    "    if path.lower().endswith('.pdf'):\n",
    "        return process_pdf(path, task, custom_prompt, page_num)\n",
    "    else:\n",
    "        return process_image(Image.open(path), task, custom_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f4c2211",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# GRADIO UI HELPER FUNCTIONS\n",
    "# ============================================================================\n",
    "def toggle_prompt(task):\n",
    "    \"\"\"Toggle prompt visibility based on selected task\"\"\"\n",
    "    if task == \"‚úèÔ∏è Custom\":\n",
    "        return gr.update(visible=True, label=\"Custom Prompt\", placeholder=\"Add <|grounding|> for bounding boxes\")\n",
    "    elif task == \"üìç Locate\":\n",
    "        return gr.update(visible=True, label=\"Text to Locate\", placeholder=\"Enter text to locate\")\n",
    "    return gr.update(visible=False)\n",
    "\n",
    "def select_boxes(task):\n",
    "    \"\"\"Auto-select boxes tab for Locate task\"\"\"\n",
    "    if task == \"üìç Locate\":\n",
    "        return gr.update(selected=\"tab_boxes\")\n",
    "    return gr.update()\n",
    "\n",
    "def get_pdf_page_count(file_path):\n",
    "    \"\"\"Get total number of pages in a PDF\"\"\"\n",
    "    if not file_path or not file_path.lower().endswith('.pdf'):\n",
    "        return 1\n",
    "    doc = fitz.open(file_path)\n",
    "    count = len(doc)\n",
    "    doc.close()\n",
    "    return count\n",
    "\n",
    "def load_image(file_path, page_num=1):\n",
    "    \"\"\"Load image from file or PDF page\"\"\"\n",
    "    if not file_path:\n",
    "        return None\n",
    "    if file_path.lower().endswith('.pdf'):\n",
    "        doc = fitz.open(file_path)\n",
    "        page_idx = max(0, min(int(page_num) - 1, len(doc) - 1))\n",
    "        page = doc.load_page(page_idx)\n",
    "        pix = page.get_pixmap(matrix=fitz.Matrix(300/72, 300/72), alpha=False)\n",
    "        img = Image.open(BytesIO(pix.tobytes(\"png\")))\n",
    "        doc.close()\n",
    "        return img\n",
    "    else:\n",
    "        return Image.open(file_path)\n",
    "\n",
    "def update_page_selector(file_path):\n",
    "    \"\"\"Update page selector visibility and range for PDFs\"\"\"\n",
    "    if not file_path:\n",
    "        return gr.update(visible=False)\n",
    "    if file_path.lower().endswith('.pdf'):\n",
    "        page_count = get_pdf_page_count(file_path)\n",
    "        return gr.update(visible=True, maximum=page_count, value=1, minimum=1,\n",
    "                        label=f\"Select Page (1-{page_count})\")\n",
    "    return gr.update(visible=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "524bcbe0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# GRADIO INTERFACE\n",
    "# ============================================================================\n",
    "with gr.Blocks(title=\"DeepSeek-OCR-2\") as demo:\n",
    "    gr.Markdown(\"\"\"\n",
    "    # üöÄ DeepSeek-OCR-2 Demo\n",
    "    **Convert documents to markdown, extract text, parse figures, and locate specific content with bounding boxes.** \n",
    "    **It's powered by DeepEncoder v2. It achieves 91.09% on OmniDocBench (+3.73% over v1).** \n",
    "    \n",
    "    Upload your own images or PDFs from your computer!\n",
    "    \"\"\")\n",
    "    \n",
    "    with gr.Row():\n",
    "        with gr.Column(scale=1):\n",
    "            file_in = gr.File(label=\"Upload Image or PDF\", file_types=[\"image\", \".pdf\"], type=\"filepath\")\n",
    "            input_img = gr.Image(label=\"Input Image\", type=\"pil\", height=300)\n",
    "            page_selector = gr.Number(label=\"Select Page\", value=1, minimum=1, step=1, visible=False)\n",
    "            task = gr.Dropdown(list(TASK_PROMPTS.keys()), value=\"üìã Markdown\", label=\"Task\")\n",
    "            prompt = gr.Textbox(label=\"Prompt\", lines=2, visible=False)\n",
    "            btn = gr.Button(\"Extract\", variant=\"primary\", size=\"lg\")\n",
    "        \n",
    "        with gr.Column(scale=2):\n",
    "            with gr.Tabs() as tabs:\n",
    "                with gr.Tab(\"Text\", id=\"tab_text\"):\n",
    "                    text_out = gr.Textbox(lines=20, show_copy_button=True, show_label=False)\n",
    "                with gr.Tab(\"Markdown Preview\", id=\"tab_markdown\"):\n",
    "                    md_out = gr.Markdown(\"\")\n",
    "                with gr.Tab(\"Boxes\", id=\"tab_boxes\"):\n",
    "                    img_out = gr.Image(type=\"pil\", height=500, show_label=False)\n",
    "                with gr.Tab(\"Cropped Images\", id=\"tab_crops\"):\n",
    "                    gallery = gr.Gallery(show_label=False, columns=3, height=400)\n",
    "                with gr.Tab(\"Raw Text\", id=\"tab_raw\"):\n",
    "                    raw_out = gr.Textbox(lines=20, show_copy_button=True, show_label=False)\n",
    "    \n",
    "    with gr.Accordion(\"‚ÑπÔ∏è Info\", open=False):\n",
    "        gr.Markdown(\"\"\"\n",
    "        ### Configuration\n",
    "        1024 base + 768 patches with dynamic cropping (2-6 patches). 144 tokens per patch + 256 base tokens.\n",
    "        \n",
    "        ### Tasks\n",
    "        - **Markdown**: Convert document to structured markdown with layout detection (grounding ‚úÖ)\n",
    "        - **Free OCR**: Simple text extraction without layout\n",
    "        - **Locate**: Find and highlight specific text/elements in image (grounding ‚úÖ)\n",
    "        - **Describe**: General image description\n",
    "        - **Custom**: Your own prompt\n",
    "        \n",
    "        ### Special Tokens\n",
    "        - `<image>` - Placeholder where visual tokens (256-1120 size) are inserted\n",
    "        - `<|grounding|>` - Enables layout detection with bounding boxes\n",
    "        - `<|ref|>text<|/ref|>` - Reference text to locate in the image\n",
    "    \n",
    "        \"\"\")\n",
    "    \n",
    "    # Event handlers\n",
    "    file_in.change(load_image, [file_in, page_selector], [input_img])\n",
    "    file_in.change(update_page_selector, [file_in], [page_selector])\n",
    "    page_selector.change(load_image, [file_in, page_selector], [input_img])\n",
    "    task.change(toggle_prompt, [task], [prompt])\n",
    "    task.change(select_boxes, [task], [tabs])\n",
    "    \n",
    "    def run(image, file_path, task, custom_prompt, page_num):\n",
    "        if file_path:\n",
    "            return process_file(file_path, task, custom_prompt, int(page_num))\n",
    "        if image is not None:\n",
    "            return process_image(image, task, custom_prompt)\n",
    "        return \"Error: Upload a file or image\", \"\", \"\", None, []\n",
    "\n",
    "    submit_event = btn.click(run, [input_img, file_in, task, prompt, page_selector],\n",
    "                             [text_out, md_out, raw_out, img_out, gallery])\n",
    "    submit_event.then(select_boxes, [task], [tabs])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9491022d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# LAUNCH GRADIO APP\n",
    "# ============================================================================\n",
    "# Run this cell to launch the Gradio interface\n",
    "# The share=True parameter will create a public link you can access\n",
    "demo.queue(max_size=20).launch(share=True, debug=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
